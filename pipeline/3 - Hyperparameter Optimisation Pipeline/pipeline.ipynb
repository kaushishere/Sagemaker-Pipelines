{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "We already have the raw data in S3 from our previous pipeline renditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Pipeline\n",
    "In addition to previous pipeline additions, we will now incorporate hyperparameter optimisation, which essentially runs multiple training jobs to find the set of hyperparameters that yield a model with the best results (e.g. highest validation accuracy).\n",
    "\n",
    "The main changes from previous pipelines are summarised below:\n",
    "* Training step has been replaced with a Tuning step. this step is what calls the estimator.fit method\n",
    "* Hyperparameters for the Decision Tree Classifier are no longer baked into the code as we will be running a hyperparameter tuning job to explore best possible hyperparameter values for **tree max depth** and **min samples split**\n",
    "* Out of the 10 models produced from tuning, we will choose the top performing model and obtain in-depth evaluation metrics (e.g. Confusion Matrix, Test Dataset Accuracy) for it\n",
    "* The model that eventually gets registered, subject to the ConditionStep, will also be the top performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo, ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    "    ParameterBoolean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    HyperparameterTuner\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high-level\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "bucket = 'sagemaker-fraud-detection-ml'\n",
    "\n",
    "# pipeline parameters\n",
    "min_validation_accuracy = ParameterFloat(\n",
    "    name='MinValidationAccuracyToRegisterModel',\n",
    "    default_value=0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "processor = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1                          \n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name='FraudDetectionProcess',\n",
    "    processor=processor,\n",
    "    code='data_processing.py',\n",
    "    inputs=[\n",
    "    \n",
    "    # define where the processor needs to look to find raw data \n",
    "        ProcessingInput(\n",
    "            input_name='raw-data',\n",
    "            source=f's3://{bucket}/raw_data.csv',\n",
    "            destination='/opt/ml/processing/input/data/',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "\n",
    "    # define where the processor needs to look to find processed data to upload to s3\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='train',\n",
    "            source='/opt/ml/processing/output/train',\n",
    "            s3_upload_mode='EndOfJob'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='validation',\n",
    "            source='/opt/ml/processing/output/validation',\n",
    "            s3_upload_mode='EndOfJob'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='test',\n",
    "            source='/opt/ml/processing/output/test',\n",
    "            s3_upload_mode='EndOfJob'\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments=['--input-data', '/opt/ml/processing/input/data/'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define processed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training inputs are dynamically linked to s3 outputs from the preprocessing step\n",
    "\n",
    "s3_input_train = TrainingInput(\n",
    "    s3_data=Join(\n",
    "        on='/', \n",
    "        values=[\n",
    "            preprocessing_step.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri,\n",
    "            'train.csv'\n",
    "        ]\n",
    "    ),\n",
    "    content_type='csv'\n",
    ")\n",
    "s3_input_validate = TrainingInput(\n",
    "    s3_data=Join(\n",
    "        on='/',\n",
    "        values=[\n",
    "            preprocessing_step.properties.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri,\n",
    "            'validation.csv'\n",
    "        ]\n",
    "    ),\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define estimator & tuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Regex tells Sagemaker what to look out for in the training logs.\n",
    "# whatever this matches, this will be reported as metrics in the Sagemaker Pipeline\n",
    "metric_definitions=metric_definitions = [\n",
    "     {'Name': 'training:accuracy', 'Regex': 'train_acc: ([0-9.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n",
    "]\n",
    "\n",
    "estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='.',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    py_version='py3',\n",
    "    framework_version='1.0-1',\n",
    "    metric_definitions=metric_definitions,\n",
    "    input_mode='File',\n",
    "    sagemaker_session=pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'max-depth': IntegerParameter(1, 10, scaling_type='Auto'),\n",
    "    'min-samples-split': IntegerParameter(1, 10, scaling_type='Auto'),\n",
    "}\n",
    "\n",
    "hyperparameter_tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name='validation:accuracy',\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    strategy='Bayesian',\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type='Maximize',\n",
    ")\n",
    "\n",
    "tuning_step = TuningStep(\n",
    "    name='TuningStep',\n",
    "    step_args=hyperparameter_tuner.fit(\n",
    "        inputs={\n",
    "            'train': s3_input_train,\n",
    "            'validation': s3_input_validate\n",
    "        }\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Step for the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1                          \n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='BestModelEvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json',\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateTopModel',\n",
    "    processor=processor,\n",
    "    code='evaluation.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=tuning_step.get_top_model_s3_uri(\n",
    "                top_k=0, # get the best model\n",
    "                s3_bucket=session.default_bucket()\n",
    "            ),\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocessing_step.properties.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='evaluation', source='/opt/ml/processing/evaluation'),\n",
    "    ],\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# convert evaluation metrics to a ModelMetrics instance so we can attach it to the model register step\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on='/', values=[\n",
    "            evaluation_step.properties.ProcessingOutputConfig.Outputs['evaluation'].S3Output.S3Uri,\n",
    "            'evaluation.json'\n",
    "        ]),\n",
    "        content_type='application/json',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register model step (if conditional step is a success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "model = Model(\n",
    "    image_uri=estimator.image_uri,\n",
    "    model_data=tuning_step.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=session.default_bucket()\n",
    "    ),\n",
    "    entry_point = estimator.entry_point, # this is necessary because the train.py entry_point contains functions to be executed during inference\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.m5.large'],\n",
    "    transform_instances=['ml.m5.large'],\n",
    "    model_package_group_name='fraud-detection-model-group',\n",
    "    approval_status='PendingManualApproval',\n",
    "    model_metrics = model_metrics\n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name='FraudDetectionRegisterModel',\n",
    "    step_args=register_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail the pipeline in the event the validation accuracy is too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_step = FailStep(\n",
    "    name='FailStep',\n",
    "    error_message=Join(on=' ', values=['Pipeline was failed due to log loss < ', min_validation_accuracy]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name='ModelRegistrationConditionStep',\n",
    "    conditions = [\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=JsonGet(\n",
    "                step_name=evaluation_step.name,\n",
    "                property_file=evaluation_report,\n",
    "                json_path='binary_classification_metrics.accuracy.value',\n",
    "            ),\n",
    "            right=min_validation_accuracy\n",
    "    )],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring steps together to form the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name='fraud-detection-model-pipeline',\n",
    "    steps=[preprocessing_step, tuning_step, condition_step, evaluation_step],\n",
    "    parameters=[min_validation_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-north-1:263108256547:pipeline/fraud-detection-model-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '73d8f4cd-0c0a-4523-a4be-d48e90b270f7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '73d8f4cd-0c0a-4523-a4be-d48e90b270f7',\n",
       "   'strict-transport-security': 'max-age=47304000; includeSubDomains',\n",
       "   'x-frame-options': 'DENY',\n",
       "   'content-security-policy': \"frame-ancestors 'none'\",\n",
       "   'cache-control': 'no-cache, no-store, must-revalidate',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '122',\n",
       "   'date': 'Sat, 25 Oct 2025 11:51:45 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# programitically start the pipeline\n",
    "# pipeline.start(\n",
    "#     execution_display_name='conditional-model-registration',\n",
    "#     execution_description='Starting from the SageMaker Studio'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
